{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S-GT0Z1qAl0",
        "outputId": "c6bf6b1f-71eb-41db-ce23-11c40f3fd5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DESCRIPCIÓN DE VARIABLES DEL DATASET DE VINOS ===\n",
            "\n",
            "Descripción general del dataset:\n",
            "Número de muestras: 178\n",
            "Número de características: 13\n",
            "Clases: [0 1 2]\n",
            "Nombres de clases: ['class_0' 'class_1' 'class_2']\n",
            "Distribución de clases: {1: 71, 0: 59, 2: 48}\n",
            "\n",
            "=== ESTADÍSTICAS DESCRIPTIVAS DE LAS VARIABLES ===\n",
            "                                                         Descripción   Media  Desv. Estándar  Mínimo  Cuartil 1  Mediana  Cuartil 3   Máximo\n",
            "alcohol                                 Contenido de alcohol (% vol)   13.00            0.81   11.03      12.36    13.05      13.68    14.83\n",
            "malic_acid                                        Ácido málico (g/L)    2.34            1.12    0.74       1.60     1.87       3.08     5.80\n",
            "ash                                                     Ceniza (g/L)    2.37            0.27    1.36       2.21     2.36       2.56     3.23\n",
            "alcalinity_of_ash                      Alcalinidad de la ceniza (pH)   19.49            3.34   10.60      17.20    19.50      21.50    30.00\n",
            "magnesium                                            Magnesio (mg/L)   99.74           14.28   70.00      88.00    98.00     107.00   162.00\n",
            "total_phenols                                 Fenoles totales (mg/L)    2.30            0.63    0.98       1.74     2.36       2.80     3.88\n",
            "flavanoids                                        Flavonoides (mg/L)    2.03            1.00    0.34       1.20     2.13       2.88     5.08\n",
            "nonflavanoid_phenols                   Fenoles no flavonoides (mg/L)    0.36            0.12    0.13       0.27     0.34       0.44     0.66\n",
            "proanthocyanins                               Proantocianinas (mg/L)    1.59            0.57    0.41       1.25     1.56       1.95     3.58\n",
            "color_intensity                    Intensidad de color (absorbancia)    5.06            2.32    1.28       3.22     4.69       6.20    13.00\n",
            "hue                                          Tonalidad (absorbancia)    0.96            0.23    0.48       0.78     0.96       1.12     1.71\n",
            "od280/od315_of_diluted_wines  OD280/OD315 de vinos diluidos (índice)    2.61            0.71    1.27       1.94     2.78       3.17     4.00\n",
            "proline                                               Prolina (mg/L)  746.89          314.91  278.00     500.50   673.50     985.00  1680.00\n",
            "\n",
            "=== IMPORTANCIA DE LAS VARIABLES PARA LA CLASIFICACIÓN ===\n",
            "                        Variable  Importancia RF  Información Mutua  Importancia Promedio\n",
            "0                     flavanoids          0.1945             0.6648                0.5972\n",
            "1                color_intensity          0.1730             0.5496                0.4999\n",
            "3                        proline          0.1370             0.5512                0.4831\n",
            "4   od280/od315_of_diluted_wines          0.1118             0.5040                0.4350\n",
            "2                        alcohol          0.1416             0.4599                0.4167\n",
            "5                            hue          0.0769             0.4559                0.3813\n",
            "6                  total_phenols          0.0351             0.4074                0.3239\n",
            "7                     malic_acid          0.0331             0.2768                0.2248\n",
            "10               proanthocyanins          0.0184             0.2687                0.2113\n",
            "8              alcalinity_of_ash          0.0299             0.2587                0.2095\n",
            "9                      magnesium          0.0259             0.1820                0.1498\n",
            "12          nonflavanoid_phenols          0.0073             0.1542                0.1196\n",
            "11                           ash          0.0155             0.0779                0.0663\n",
            "\n",
            "Informe de descripción de variables guardado en 'descripcion_variables_vino.csv' y 'descripcion_variables_vino.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cargar dataset de vinos\n",
        "wine = load_wine()\n",
        "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = wine.target\n",
        "\n",
        "# Descripción de las variables\n",
        "print(\"=== DESCRIPCIÓN DE VARIABLES DEL DATASET DE VINOS ===\")\n",
        "print(\"\\nDescripción general del dataset:\")\n",
        "print(f\"Número de muestras: {X.shape[0]}\")\n",
        "print(f\"Número de características: {X.shape[1]}\")\n",
        "print(f\"Clases: {np.unique(y)}\")\n",
        "print(f\"Nombres de clases: {wine.target_names}\")\n",
        "print(f\"Distribución de clases: {pd.Series(y).value_counts().to_dict()}\")\n",
        "\n",
        "# Crear un DataFrame con la descripción de las variables\n",
        "variable_descriptions = {\n",
        "    'alcohol': 'Contenido de alcohol (% vol)',\n",
        "    'malic_acid': 'Ácido málico (g/L)',\n",
        "    'ash': 'Ceniza (g/L)',\n",
        "    'alcalinity_of_ash': 'Alcalinidad de la ceniza (pH)',\n",
        "    'magnesium': 'Magnesio (mg/L)',\n",
        "    'total_phenols': 'Fenoles totales (mg/L)',\n",
        "    'flavanoids': 'Flavonoides (mg/L)',\n",
        "    'nonflavanoid_phenols': 'Fenoles no flavonoides (mg/L)',\n",
        "    'proanthocyanins': 'Proantocianinas (mg/L)',\n",
        "    'color_intensity': 'Intensidad de color (absorbancia)',\n",
        "    'hue': 'Tonalidad (absorbancia)',\n",
        "    'od280/od315_of_diluted_wines': 'OD280/OD315 de vinos diluidos (índice)',\n",
        "    'proline': 'Prolina (mg/L)'\n",
        "}\n",
        "\n",
        "# Estadísticas descriptivas\n",
        "stats = X.describe().T\n",
        "stats['descripcion'] = pd.Series(variable_descriptions)\n",
        "stats = stats[['descripcion', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
        "stats = stats.rename(columns={\n",
        "    'mean': 'Media',\n",
        "    'std': 'Desv. Estándar',\n",
        "    'min': 'Mínimo',\n",
        "    '25%': 'Cuartil 1',\n",
        "    '50%': 'Mediana',\n",
        "    '75%': 'Cuartil 3',\n",
        "    'max': 'Máximo',\n",
        "    'descripcion': 'Descripción'\n",
        "})\n",
        "\n",
        "print(\"\\n=== ESTADÍSTICAS DESCRIPTIVAS DE LAS VARIABLES ===\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(stats.round(2))\n",
        "\n",
        "# Visualizar la distribución de cada variable por clase\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(X.columns):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    for target in np.unique(y):\n",
        "        plt.hist(X[feature][y == target], alpha=0.5, label=wine.target_names[target], bins=15)\n",
        "    plt.xlabel(feature)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.tight_layout()\n",
        "plt.savefig('distribucion_variables_por_clase.png')\n",
        "plt.close()\n",
        "\n",
        "# Correlación entre variables\n",
        "plt.figure(figsize=(14, 10))\n",
        "correlation = X.corr(method='spearman')\n",
        "mask = np.triu(correlation)\n",
        "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm', mask=mask)\n",
        "plt.title('Matriz de Correlación entre Variables')\n",
        "plt.tight_layout()\n",
        "plt.savefig('matriz_correlacion_detallada.png')\n",
        "plt.close()\n",
        "\n",
        "# Importancia de las variables para la clasificación\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Importancia basada en Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "importances = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Importancia RF': rf.feature_importances_\n",
        "}).sort_values('Importancia RF', ascending=False)\n",
        "\n",
        "# Importancia basada en Información Mutua\n",
        "mi_scores = mutual_info_classif(X, y)\n",
        "mi_importances = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Información Mutua': mi_scores\n",
        "}).sort_values('Información Mutua', ascending=False)\n",
        "\n",
        "# Combinar ambas métricas\n",
        "importances = importances.merge(mi_importances, on='Variable')\n",
        "importances['Importancia Promedio'] = (importances['Importancia RF'] +\n",
        "                                      importances['Información Mutua'] / importances['Información Mutua'].max()) / 2\n",
        "importances = importances.sort_values('Importancia Promedio', ascending=False)\n",
        "\n",
        "print(\"\\n=== IMPORTANCIA DE LAS VARIABLES PARA LA CLASIFICACIÓN ===\")\n",
        "print(importances.round(4))\n",
        "\n",
        "# Visualizar importancia de variables\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(importances['Variable'], importances['Importancia Promedio'], color='teal')\n",
        "plt.xlabel('Importancia Promedio')\n",
        "plt.ylabel('Variable')\n",
        "plt.title('Importancia de Variables para la Clasificación')\n",
        "plt.tight_layout()\n",
        "plt.savefig('importancia_variables.png')\n",
        "plt.close()\n",
        "\n",
        "# Visualizar distribución de clases\n",
        "plt.figure(figsize=(8, 6))\n",
        "class_counts = pd.Series(y).value_counts().sort_index()\n",
        "plt.bar(wine.target_names, class_counts, color=['red', 'green', 'blue'])\n",
        "plt.xlabel('Clase de Vino')\n",
        "plt.ylabel('Número de Muestras')\n",
        "plt.title('Distribución de Clases en el Dataset')\n",
        "for i, count in enumerate(class_counts):\n",
        "    plt.text(i, count + 1, str(count), ha='center')\n",
        "plt.tight_layout()\n",
        "plt.savefig('distribucion_clases_detallada.png')\n",
        "plt.close()\n",
        "\n",
        "# Análisis de separabilidad de clases con PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for target in np.unique(y):\n",
        "    plt.scatter(X_pca[y == target, 0], X_pca[y == target, 1],\n",
        "                label=wine.target_names[target], alpha=0.7,\n",
        "                edgecolors='k', s=80)\n",
        "plt.xlabel(f'Componente Principal 1 ({pca.explained_variance_ratio_[0]:.2%} varianza)')\n",
        "plt.ylabel(f'Componente Principal 2 ({pca.explained_variance_ratio_[1]:.2%} varianza)')\n",
        "plt.title('Separación de Clases de Vino usando PCA')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('separacion_clases_pca.png')\n",
        "plt.close()\n",
        "\n",
        "# Crear un documento con toda la información\n",
        "report = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Descripción': [variable_descriptions[col] for col in X.columns],\n",
        "    'Media': X.mean().values,\n",
        "    'Desv. Estándar': X.std().values,\n",
        "    'Importancia': importances.set_index('Variable')['Importancia Promedio'].reindex(X.columns).values\n",
        "})\n",
        "\n",
        "# Guardar el informe\n",
        "report.to_csv('descripcion_variables_vino.csv', index=False)\n",
        "report.to_excel('descripcion_variables_vino.xlsx', index=False)\n",
        "\n",
        "print(\"\\nInforme de descripción de variables guardado en 'descripcion_variables_vino.csv' y 'descripcion_variables_vino.xlsx'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, make_scorer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer, RobustScaler\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cargar dataset de vinos (clasificación multiclase)\n",
        "wine = load_wine()\n",
        "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = wine.target\n",
        "\n",
        "# Dividir los datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Verificar el desbalance inicial\n",
        "print(\"=== DISTRIBUCIÓN ORIGINAL DE CLASES (TRAIN) ===\")\n",
        "train_class_counts = pd.Series(y_train).value_counts()\n",
        "print(train_class_counts)\n",
        "print(f\"Proporción: {pd.Series(y_train).value_counts(normalize=True).round(2)}\")\n",
        "\n",
        "# Función para evaluar y mostrar resultados\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # F1-Score\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_by_class = f1_score(y_test, y_pred, average=None)\n",
        "\n",
        "    # Matriz de confusión\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Reporte de clasificación\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Visualizar matriz de confusión\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=np.unique(y),\n",
        "                yticklabels=np.unique(y))\n",
        "    plt.title(f'Matriz de Confusión - {model_name}')\n",
        "    plt.xlabel('Predicción')\n",
        "    plt.ylabel('Valor Real')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Resultados\n",
        "    print(f\"\\n=== RESULTADOS DEL MODELO: {model_name} ===\")\n",
        "    print(f\"F1-Score (weighted): {f1:.4f}\")\n",
        "    print(f\"F1-Score por clase: {f1_by_class}\")\n",
        "    print(\"\\nMatriz de Confusión:\")\n",
        "    print(cm)\n",
        "    print(\"\\nReporte de Clasificación:\")\n",
        "    print(report)\n",
        "\n",
        "    return f1, f1_by_class, cm\n",
        "\n",
        "# 1. MODELO ORIGINAL (BASELINE)\n",
        "print(\"\\n=== MODELO ORIGINAL (BASELINE) ===\")\n",
        "dt_original = DecisionTreeClassifier(random_state=42)\n",
        "dt_original.fit(X_train, y_train)\n",
        "f1_original, f1_by_class_original, _ = evaluate_model(dt_original, X_test, y_test, \"Original\")\n",
        "\n",
        "# 2. ESTRATEGIA 1: TRANSFORMACIÓN AVANZADA DE CARACTERÍSTICAS\n",
        "print(\"\\n=== ESTRATEGIA 1: TRANSFORMACIÓN AVANZADA DE CARACTERÍSTICAS ===\")\n",
        "\n",
        "# Probar diferentes transformadores para encontrar el mejor\n",
        "transformers = {\n",
        "    'PowerTransformer': PowerTransformer(method='yeo-johnson'),\n",
        "    'QuantileTransformer': QuantileTransformer(output_distribution='normal'),\n",
        "    'RobustScaler': RobustScaler()\n",
        "}\n",
        "\n",
        "best_transformer = None\n",
        "best_f1 = 0\n",
        "\n",
        "for name, transformer in transformers.items():\n",
        "    # Transformar datos\n",
        "    X_train_transformed = transformer.fit_transform(X_train)\n",
        "    X_test_transformed = transformer.transform(X_test)\n",
        "\n",
        "    # Entrenar modelo básico\n",
        "    dt = DecisionTreeClassifier(random_state=42)\n",
        "    dt.fit(X_train_transformed, y_train)\n",
        "\n",
        "    # Evaluar\n",
        "    y_pred = dt.predict(X_test_transformed)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"F1-Score con {name}: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_transformer = transformer\n",
        "\n",
        "print(f\"\\nMejor transformador: {type(best_transformer).__name__}\")\n",
        "\n",
        "# Aplicar el mejor transformador\n",
        "X_train_transformed = best_transformer.fit_transform(X_train)\n",
        "X_test_transformed = best_transformer.transform(X_test)\n",
        "\n",
        "# 3. ESTRATEGIA 2: OPTIMIZACIÓN EXHAUSTIVA DE HIPERPARÁMETROS\n",
        "print(\"\\n=== ESTRATEGIA 2: OPTIMIZACIÓN EXHAUSTIVA DE HIPERPARÁMETROS ===\")\n",
        "\n",
        "# Crear un scorer personalizado basado en F1\n",
        "f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "# Grid de hiperparámetros más exhaustivo\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 5, 10, 15, 20, 25, 30],\n",
        "    'min_samples_split': [2, 3, 5, 7, 10],\n",
        "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'max_features': [None, 'sqrt', 'log2', 0.7, 0.8, 0.9],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'ccp_alpha': [0.0, 0.01, 0.02, 0.03, 0.05]  # Pruning para evitar overfitting\n",
        "}\n",
        "\n",
        "# Usar RandomizedSearchCV para explorar más eficientemente\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=100,  # Número de combinaciones a probar\n",
        "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
        "    scoring=f1_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X_train_transformed, y_train)\n",
        "print(f\"\\nMejores parámetros: {random_search.best_params_}\")\n",
        "print(f\"Mejor F1-Score CV: {random_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluar modelo con hiperparámetros optimizados\n",
        "dt_optimized = random_search.best_estimator_\n",
        "f1_optimized, f1_by_class_optimized, _ = evaluate_model(dt_optimized, X_test_transformed, y_test, \"Hiperparámetros Optimizados\")\n",
        "\n",
        "# 4. ESTRATEGIA 3: BALANCEO AVANZADO + ÁRBOL DE DECISIÓN OPTIMIZADO\n",
        "print(\"\\n=== ESTRATEGIA 3: BALANCEO AVANZADO + ÁRBOL DE DECISIÓN OPTIMIZADO ===\")\n",
        "\n",
        "# Probar diferentes técnicas de balanceo\n",
        "balancers = {\n",
        "    'SMOTE': SMOTE(random_state=42),\n",
        "    'ADASYN': ADASYN(random_state=42),\n",
        "    'SMOTEENN': SMOTEENN(random_state=42),\n",
        "    'SMOTETomek': SMOTETomek(random_state=42)\n",
        "}\n",
        "\n",
        "best_balancer = None\n",
        "best_f1_balancer = 0\n",
        "\n",
        "for name, balancer in balancers.items():\n",
        "    # Crear pipeline con balanceo y árbol optimizado\n",
        "    pipeline = ImbPipeline([\n",
        "        ('transformer', best_transformer),\n",
        "        ('balancer', balancer),\n",
        "        ('classifier', DecisionTreeClassifier(**random_search.best_params_, random_state=42))\n",
        "    ])\n",
        "\n",
        "    # Entrenar\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluar\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"F1-Score con {name}: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1_balancer:\n",
        "        best_f1_balancer = f1\n",
        "        best_balancer = balancer\n",
        "\n",
        "print(f\"\\nMejor técnica de balanceo: {type(best_balancer).__name__}\")\n",
        "\n",
        "# Crear pipeline final con el mejor balanceador\n",
        "pipeline_final = ImbPipeline([\n",
        "    ('transformer', best_transformer),\n",
        "    ('balancer', best_balancer),\n",
        "    ('classifier', DecisionTreeClassifier(**random_search.best_params_, random_state=42))\n",
        "])\n",
        "\n",
        "# Entrenar pipeline final\n",
        "pipeline_final.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar pipeline final\n",
        "f1_pipeline, f1_by_class_pipeline, _ = evaluate_model(pipeline_final, X_test, y_test, \"Pipeline Final\")\n",
        "\n",
        "# 5. ESTRATEGIA 4: FEATURE ENGINEERING MANUAL + ÁRBOL OPTIMIZADO\n",
        "print(\"\\n=== ESTRATEGIA 4: FEATURE ENGINEERING MANUAL + ÁRBOL OPTIMIZADO ===\")\n",
        "\n",
        "# Crear características adicionales basadas en conocimiento del dominio\n",
        "X_train_fe = X_train.copy()\n",
        "X_test_fe = X_test.copy()\n",
        "\n",
        "# Ratios entre características (pueden capturar relaciones importantes)\n",
        "X_train_fe['alcohol_ash_ratio'] = X_train['alcohol'] / X_train['ash']\n",
        "X_test_fe['alcohol_ash_ratio'] = X_test['alcohol'] / X_test['ash']\n",
        "\n",
        "X_train_fe['flavanoids_phenols_ratio'] = X_train['flavanoids'] / X_train['total_phenols']\n",
        "X_test_fe['flavanoids_phenols_ratio'] = X_test['flavanoids'] / X_test['total_phenols']\n",
        "\n",
        "X_train_fe['color_hue_ratio'] = X_train['color_intensity'] / X_train['hue']\n",
        "X_test_fe['color_hue_ratio'] = X_test['color_intensity'] / X_test['hue']\n",
        "\n",
        "# Productos entre características importantes (según información mutua)\n",
        "mi_scores = mutual_info_classif(X_train, y_train)\n",
        "mi_features = pd.DataFrame({'Feature': X.columns, 'MI_Score': mi_scores})\n",
        "top_features = mi_features.sort_values('MI_Score', ascending=False)['Feature'].iloc[:3].values\n",
        "\n",
        "for i, feat1 in enumerate(top_features):\n",
        "    for feat2 in top_features[i+1:]:\n",
        "        feat_name = f\"{feat1}_{feat2}_product\"\n",
        "        X_train_fe[feat_name] = X_train[feat1] * X_train[feat2]\n",
        "        X_test_fe[feat_name] = X_test[feat1] * X_test[feat2]\n",
        "\n",
        "# Transformar datos con feature engineering\n",
        "X_train_fe_transformed = best_transformer.fit_transform(X_train_fe)\n",
        "X_test_fe_transformed = best_transformer.transform(X_test_fe)\n",
        "\n",
        "# Entrenar modelo con feature engineering\n",
        "dt_fe = DecisionTreeClassifier(**random_search.best_params_, random_state=42)\n",
        "dt_fe.fit(X_train_fe_transformed, y_train)\n",
        "\n",
        "# Evaluar modelo con feature engineering\n",
        "f1_fe, f1_by_class_fe, _ = evaluate_model(dt_fe, X_test_fe_transformed, y_test, \"Feature Engineering\")\n",
        "\n",
        "# 6. ESTRATEGIA 5: COMBINACIÓN DE TODAS LAS TÉCNICAS\n",
        "print(\"\\n=== ESTRATEGIA 5: COMBINACIÓN DE TODAS LAS TÉCNICAS ===\")\n",
        "\n",
        "# Crear pipeline final con todas las mejoras\n",
        "pipeline_combined = ImbPipeline([\n",
        "    ('transformer', best_transformer),\n",
        "    ('balancer', best_balancer),\n",
        "    ('classifier', DecisionTreeClassifier(**random_search.best_params_, random_state=42))\n",
        "])\n",
        "\n",
        "# Entrenar con datos que incluyen feature engineering\n",
        "pipeline_combined.fit(X_train_fe, y_train)\n",
        "\n",
        "# Evaluar pipeline combinado\n",
        "f1_combined, f1_by_class_combined, _ = evaluate_model(pipeline_combined, X_test_fe, y_test, \"Combinación Final\")\n",
        "\n",
        "# Visualizar el árbol final para entender su estructura\n",
        "plt.figure(figsize=(20, 10))\n",
        "tree_model = pipeline_combined.named_steps['classifier']\n",
        "plot_tree(tree_model,\n",
        "          feature_names=X_test_fe.columns,\n",
        "          class_names=[str(i) for i in range(3)],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          max_depth=3)  # Limitar profundidad para visualización\n",
        "plt.savefig('arbol_decision_final.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Comparar todos los modelos\n",
        "print(\"\\n=== COMPARACIÓN DE TODOS LOS MODELOS ===\")\n",
        "models = ['Original', 'Hiperparámetros Optimizados', 'Pipeline Final', 'Feature Engineering', 'Combinación Final']\n",
        "f1_scores = [f1_original, f1_optimized, f1_pipeline, f1_fe, f1_combined]\n",
        "f1_by_class_all = [f1_by_class_original, f1_by_class_optimized, f1_by_class_pipeline, f1_by_class_fe, f1_by_class_combined]\n",
        "\n",
        "# Crear DataFrame para resultados\n",
        "results = pd.DataFrame({\n",
        "    'Modelo': models,\n",
        "    'F1-Score (Weighted)': f1_scores,\n",
        "    'F1-Score (Clase 0)': [f[0] for f in f1_by_class_all],\n",
        "    'F1-Score (Clase 1)': [f[1] for f in f1_by_class_all],\n",
        "    'F1-Score (Clase 2)': [f[2] for f in f1_by_class_all],\n",
        "})\n",
        "\n",
        "# Calcular la desviación estándar de F1-scores entre clases (medida de equidad)\n",
        "results['Desviación F1 entre clases'] = results[['F1-Score (Clase 0)', 'F1-Score (Clase 1)', 'F1-Score (Clase 2)']].std(axis=1)\n",
        "\n",
        "print(results)\n",
        "\n",
        "# Visualizar comparación de F1-scores\n",
        "plt.figure(figsize=(14, 8))\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(models))\n",
        "\n",
        "plt.bar(index, results['F1-Score (Weighted)'], bar_width, label='F1 Weighted')\n",
        "plt.bar(index + bar_width, results['F1-Score (Clase 0)'], bar_width, label='F1 Clase 0')\n",
        "plt.bar(index + 2*bar_width, results['F1-Score (Clase 1)'], bar_width, label='F1 Clase 1')\n",
        "plt.bar(index + 3*bar_width, results['F1-Score (Clase 2)'], bar_width, label='F1 Clase 2')\n",
        "\n",
        "plt.xlabel('Modelo')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.title('Comparación de F1-Scores por Modelo y Clase')\n",
        "plt.xticks(index + 1.5*bar_width, models, rotation=15)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('f1_comparison_decision_tree.png')\n",
        "plt.close()\n",
        "\n",
        "# Visualizar desviación estándar (equidad entre clases)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, results['Desviación F1 entre clases'], color='purple')\n",
        "plt.xlabel('Modelo')\n",
        "plt.ylabel('Desviación Estándar de F1 entre Clases')\n",
        "plt.title('Equidad de Clasificación entre Clases (menor es mejor)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig('fairness_comparison_decision_tree.png')\n",
        "plt.close()\n",
        "\n",
        "# Identificar el mejor modelo\n",
        "best_model_idx = results['F1-Score (Weighted)'].idxmax()\n",
        "best_model_name = results.loc[best_model_idx, 'Modelo']\n",
        "best_f1 = results.loc[best_model_idx, 'F1-Score (Weighted)']\n",
        "best_fairness = results.loc[best_model_idx, 'Desviación F1 entre clases']\n",
        "\n",
        "print(f\"\\n=== MEJOR MODELO: {best_model_name} ===\")\n",
        "print(f\"F1-Score: {best_f1:.4f}\")\n",
        "print(f\"Desviación entre clases: {best_fairness:.4f}\")\n",
        "\n",
        "# Comparar con el modelo original\n",
        "original_f1 = results.loc[0, 'F1-Score (Weighted)']\n",
        "original_fairness = results.loc[0, 'Desviación F1 entre clases']\n",
        "\n",
        "print(\"\\n=== COMPARACIÓN CON MODELO ORIGINAL ===\")\n",
        "print(f\"Mejora en F1-Score: {(best_f1 - original_f1) / original_f1 * 100:.2f}%\")\n",
        "print(f\"Mejora en equidad: {(original_fairness - best_fairness) / original_fairness * 100:.2f}%\")\n",
        "\n",
        "# Guardar resultados\n",
        "results.to_csv('resultados_decision_tree.csv', index=False)\n",
        "results.to_excel('resultados_decision_tree.xlsx', index=False)\n",
        "\n",
        "print(\"\\nResultados guardados en 'resultados_decision_tree.csv' y 'resultados_decision_tree.xlsx'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPOCAOVVrfpF",
        "outputId": "96bf87fb-c850-4ee8-f9ea-725f8602e870"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DISTRIBUCIÓN ORIGINAL DE CLASES (TRAIN) ===\n",
            "1    50\n",
            "0    41\n",
            "2    33\n",
            "Name: count, dtype: int64\n",
            "Proporción: 1    0.40\n",
            "0    0.33\n",
            "2    0.27\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "=== MODELO ORIGINAL (BASELINE) ===\n",
            "\n",
            "=== RESULTADOS DEL MODELO: Original ===\n",
            "F1-Score (weighted): 0.9632\n",
            "F1-Score por clase: [0.97142857 0.95454545 0.96551724]\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[17  1  0]\n",
            " [ 0 21  0]\n",
            " [ 0  1 14]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        18\n",
            "           1       0.91      1.00      0.95        21\n",
            "           2       1.00      0.93      0.97        15\n",
            "\n",
            "    accuracy                           0.96        54\n",
            "   macro avg       0.97      0.96      0.96        54\n",
            "weighted avg       0.97      0.96      0.96        54\n",
            "\n",
            "\n",
            "=== ESTRATEGIA 1: TRANSFORMACIÓN AVANZADA DE CARACTERÍSTICAS ===\n",
            "F1-Score con PowerTransformer: 0.9632\n",
            "F1-Score con QuantileTransformer: 0.9814\n",
            "F1-Score con RobustScaler: 0.9632\n",
            "\n",
            "Mejor transformador: QuantileTransformer\n",
            "\n",
            "=== ESTRATEGIA 2: OPTIMIZACIÓN EXHAUSTIVA DE HIPERPARÁMETROS ===\n",
            "\n",
            "Mejores parámetros: {'splitter': 'random', 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 20, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.05}\n",
            "Mejor F1-Score CV: 0.9202\n",
            "\n",
            "=== RESULTADOS DEL MODELO: Hiperparámetros Optimizados ===\n",
            "F1-Score (weighted): 0.8892\n",
            "F1-Score por clase: [0.91428571 0.88372093 0.86666667]\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[16  2  0]\n",
            " [ 0 19  2]\n",
            " [ 1  1 13]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.91        18\n",
            "           1       0.86      0.90      0.88        21\n",
            "           2       0.87      0.87      0.87        15\n",
            "\n",
            "    accuracy                           0.89        54\n",
            "   macro avg       0.89      0.89      0.89        54\n",
            "weighted avg       0.89      0.89      0.89        54\n",
            "\n",
            "\n",
            "=== ESTRATEGIA 3: BALANCEO AVANZADO + ÁRBOL DE DECISIÓN OPTIMIZADO ===\n",
            "F1-Score con SMOTE: 0.8289\n",
            "F1-Score con ADASYN: 0.9047\n",
            "F1-Score con SMOTEENN: 0.8518\n",
            "F1-Score con SMOTETomek: 0.9070\n",
            "\n",
            "Mejor técnica de balanceo: SMOTETomek\n",
            "\n",
            "=== RESULTADOS DEL MODELO: Pipeline Final ===\n",
            "F1-Score (weighted): 0.9070\n",
            "F1-Score por clase: [0.91891892 0.87804878 0.93333333]\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[17  1  0]\n",
            " [ 2 18  1]\n",
            " [ 0  1 14]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.92        18\n",
            "           1       0.90      0.86      0.88        21\n",
            "           2       0.93      0.93      0.93        15\n",
            "\n",
            "    accuracy                           0.91        54\n",
            "   macro avg       0.91      0.91      0.91        54\n",
            "weighted avg       0.91      0.91      0.91        54\n",
            "\n",
            "\n",
            "=== ESTRATEGIA 4: FEATURE ENGINEERING MANUAL + ÁRBOL OPTIMIZADO ===\n",
            "\n",
            "=== RESULTADOS DEL MODELO: Feature Engineering ===\n",
            "F1-Score (weighted): 0.9630\n",
            "F1-Score por clase: [0.97142857 0.95238095 0.96774194]\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[17  1  0]\n",
            " [ 0 20  1]\n",
            " [ 0  0 15]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        18\n",
            "           1       0.95      0.95      0.95        21\n",
            "           2       0.94      1.00      0.97        15\n",
            "\n",
            "    accuracy                           0.96        54\n",
            "   macro avg       0.96      0.97      0.96        54\n",
            "weighted avg       0.96      0.96      0.96        54\n",
            "\n",
            "\n",
            "=== ESTRATEGIA 5: COMBINACIÓN DE TODAS LAS TÉCNICAS ===\n",
            "\n",
            "=== RESULTADOS DEL MODELO: Combinación Final ===\n",
            "F1-Score (weighted): 0.9247\n",
            "F1-Score por clase: [0.94444444 0.93333333 0.88888889]\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[17  1  0]\n",
            " [ 0 21  0]\n",
            " [ 1  2 12]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        18\n",
            "           1       0.88      1.00      0.93        21\n",
            "           2       1.00      0.80      0.89        15\n",
            "\n",
            "    accuracy                           0.93        54\n",
            "   macro avg       0.94      0.91      0.92        54\n",
            "weighted avg       0.93      0.93      0.92        54\n",
            "\n",
            "\n",
            "=== COMPARACIÓN DE TODOS LOS MODELOS ===\n",
            "                        Modelo  F1-Score (Weighted)  F1-Score (Clase 0)  F1-Score (Clase 1)  F1-Score (Clase 2)  Desviación F1 entre clases\n",
            "0                     Original             0.963221            0.971429            0.954545            0.965517                    0.008567\n",
            "1  Hiperparámetros Optimizados             0.889172            0.914286            0.883721            0.866667                    0.024127\n",
            "2               Pipeline Final             0.907029            0.918919            0.878049            0.933333                    0.028678\n",
            "3          Feature Engineering             0.962997            0.971429            0.952381            0.967742                    0.010102\n",
            "4            Combinación Final             0.924691            0.944444            0.933333            0.888889                    0.029397\n",
            "\n",
            "=== MEJOR MODELO: Original ===\n",
            "F1-Score: 0.9632\n",
            "Desviación entre clases: 0.0086\n",
            "\n",
            "=== COMPARACIÓN CON MODELO ORIGINAL ===\n",
            "Mejora en F1-Score: 0.00%\n",
            "Mejora en equidad: 0.00%\n",
            "\n",
            "Resultados guardados en 'resultados_decision_tree.csv' y 'resultados_decision_tree.xlsx'\n"
          ]
        }
      ]
    }
  ]
}